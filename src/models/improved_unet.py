"""
ImprovedUNet: State-of-the-art architecture for check tampering detection

Combines best practices from the expert team:
- Dr. Kaiming He: ResNet34 encoder + attention mechanisms
- Dr. Ross Girshick: Advanced training & loss design
- Dr. Liang-Chieh Chen: Multi-scale features (ASPP)
- Dr. Alexey Dosovitskiy: Hybrid CNN architecture
- Dr. Sergey Zagoruyko: Efficiency optimizations

Architecture:
    Encoder: ResNet34 (pretrained on ImageNet)
    Bottleneck: ASPP module (multi-scale context)
    Decoder: 4 upsampling stages with CBAM attention
    Output: 1 channel tamper probability map
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.models import resnet34, ResNet34_Weights

from .modules.aspp import ASPP
from .modules.cbam import CBAM


class DecoderBlock(nn.Module):
    """
    Decoder block with upsampling, skip connection, and CBAM attention
    """
    def __init__(self, in_channels, skip_channels, out_channels, use_attention=True):
        super(DecoderBlock, self).__init__()
        
        self.upsample = nn.ConvTranspose2d(
            in_channels, in_channels // 2, kernel_size=2, stride=2
        )
        
        # Channel alignment for skip connection
        self.skip_conv = nn.Conv2d(skip_channels, in_channels // 2, kernel_size=1)
        
        # Double conv after concatenation
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
        
        # Attention
        self.use_attention = use_attention
        if use_attention:
            self.attention = CBAM(out_channels)
    
    def forward(self, x, skip):
        # Upsample
        x = self.upsample(x)
        
        # Align skip connection
        skip = self.skip_conv(skip)
        
        # Concatenate
        x = torch.cat([x, skip], dim=1)
        
        # Conv
        x = self.conv(x)
        
        # Attention
        if self.use_attention:
            x = self.attention(x)
        
        return x


class ImprovedUNet(nn.Module):
    """
    Improved U-Net for check tampering detection
    
    Features:
    1. Pre-trained ResNet34 encoder (transfer learning from ImageNet)
    2. ASPP bottleneck for multi-scale context
    3. CBAM attention in decoder stages
    4. Deep supervision (optional)
    
    Args:
        n_channels: Number of input channels (default: 3 for RGB)
        n_classes: Number of output classes (default: 1 for binary segmentation)
        pretrained: Use ImageNet pre-trained weights (default: True)
        freeze_encoder: Freeze encoder weights (default: False)
        use_attention: Use CBAM attention (default: True)
    
    Example:
        >>> model = ImprovedUNet(pretrained=True)
        >>> x = torch.randn(4, 3, 512, 512)
        >>> out = model(x)
        >>> out.shape
        torch.Size([4, 1, 512, 512])
    """
    def __init__(
        self,
        n_channels=3,
        n_classes=1,
        pretrained=True,
        freeze_encoder=False,
        use_attention=True
    ):
        super(ImprovedUNet, self).__init__()
        
        # Load pre-trained ResNet34
        if pretrained:
            weights = ResNet34_Weights.IMAGENET1K_V1
            resnet = resnet34(weights=weights)
        else:
            resnet = resnet34(weights=None)
        
        # Encoder (ResNet34 stages)
        self.encoder1 = nn.Sequential(
            resnet.conv1,
            resnet.bn1,
            resnet.relu,
            resnet.maxpool
        )  # 64 channels
        
        self.encoder2 = resnet.layer1  # 64 channels
        self.encoder3 = resnet.layer2  # 128 channels
        self.encoder4 = resnet.layer3  # 256 channels
        self.encoder5 = resnet.layer4  # 512 channels
        
        # Freeze encoder if specified
        if freeze_encoder:
            for param in [self.encoder1, self.encoder2, self.encoder3, 
                         self.encoder4, self.encoder5]:
                for p in param.parameters():
                    p.requires_grad = False
        
        # Bottleneck: ASPP for multi-scale context
        self.aspp = ASPP(in_channels=512, out_channels=256)
        
        # Decoder (fixed channel dimensions to match ASPP output)
        self.decoder4 = DecoderBlock(256, 256, 256, use_attention)  # ASPP outputs 256
        self.decoder3 = DecoderBlock(256, 128, 128, use_attention)
        self.decoder2 = DecoderBlock(128, 64, 64, use_attention)
        self.decoder1 = DecoderBlock(64, 64, 32, use_attention)
        
        # Final upscaling and prediction
        self.final_upsample = nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2)
        self.final_conv = nn.Conv2d(32, n_classes, kernel_size=1)
    
    def forward(self, x):
        # Encoder (ResNet34 stages)
        # Input: (B, 3, 512, 512)
        e1 = self.encoder1(x)      # (B, 64, 128, 128) - maxpool reduces to /4
        e2 = self.encoder2(e1)     # (B, 64, 128, 128) - no spatial change
        e3 = self.encoder3(e2)     # (B, 128, 64, 64) - stride 2
        e4 = self.encoder4(e3)     # (B, 256, 32, 32) - stride 2
        e5 = self.encoder5(e4)     # (B, 512, 16, 16) - stride 2
        
        # Bottleneck: ASPP
        bottleneck = self.aspp(e5)  # (B, 256, 16, 16)
        
        # Decoder with skip connections
        # We need to match spatial dimensions carefully
        d4 = self.decoder4(bottleneck, e4)  # (B, 256, 32, 32) - upsample x2
        d3 = self.decoder3(d4, e3)          # (B, 128, 64, 64) - upsample x2
        d2 = self.decoder2(d3, e2)          # (B, 64, 128, 128) - upsample x2
        
        # For final decoder, we need to handle the transition
        # e1 is (64, 128, 128), we're coming from d2 (64, 128, 128)
        d1 = self.decoder1(d2, e1)          # (B, 32, 256, 256) - upsample x2
        
        # Final upsample to match input size
        out = self.final_upsample(d1)  # (B, 32, 512, 512) - upsample x2
        out = self.final_conv(out)     # (B, 1, 512, 512)
        
        return out
    
    def get_num_params(self):
        """Count total and trainable parameters"""
        total = sum(p.numel() for p in self.parameters())
        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)
        return total, trainable


if __name__ == "__main__":
    # Quick test
    print("=" * 70)
    print("Testing ImprovedUNet")
    print("=" * 70)
    
    # Test with different configurations
    configs = [
        {"pretrained": True, "use_attention": True, "name": "Full (Pretrained + Attention)"},
        {"pretrained": False, "use_attention": True, "name": "No Pretrain"},
        {"pretrained": True, "use_attention": False, "name": "No Attention"},
    ]
    
    for i, config in enumerate(configs):
        print(f"\n[Config {i+1}] {config['name']}")
        print("-" * 70)
        
        model = ImprovedUNet(
            pretrained=config['pretrained'],
            use_attention=config['use_attention']
        )
        
        # Test forward pass
        batch_size = 2
        x = torch.randn(batch_size, 3, 512, 512)
        
        print(f"Input shape: {x.shape}")
        
        with torch.no_grad():
            out = model(x)
        
        print(f"Output shape: {out.shape}")
        
        expected_shape = (batch_size, 1, 512, 512)
        assert out.shape == expected_shape, f"Expected {expected_shape}, got {out.shape}"
        
        # Count parameters
        total, trainable = model.get_num_params()
        print(f"Total parameters: {total:,}")
        print(f"Trainable parameters: {trainable:,}")
        print(f"Non-trainable: {total - trainable:,}")
        
        print("âœ“ Test passed!")
    
    print("\n" + "=" * 70)
    print("All tests completed successfully!")
    print("=" * 70)
